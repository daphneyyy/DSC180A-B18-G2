{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81173dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e7e3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the dataset and load the data.\n",
    "# this dataset is the original dataset \n",
    "# and does not contain the dates and times.\n",
    "file = 'Transacation_outflows_3k.pqt'\n",
    "data = pd.read_parquet(file, engine='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f52cb941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if a GPU is available, and use it if possible, otherwise use the CPU\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09bc75a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo_clean</th>\n",
       "      <th>amount</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>20.98</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>CASH APP*FREE XXXXXXXXXX CA XX/XX</td>\n",
       "      <td>200.00</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>293.49</td>\n",
       "      <td>LOAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_1</td>\n",
       "      <td>SELF_TRANSFER</td>\n",
       "      <td>280.00</td>\n",
       "      <td>SELF_TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_1</td>\n",
       "      <td>EXTERNAL_TRANSFER</td>\n",
       "      <td>47.83</td>\n",
       "      <td>EXTERNAL_TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>SELF_TRANSFER</td>\n",
       "      <td>25.00</td>\n",
       "      <td>SELF_TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>GIFTS_DONATIONS</td>\n",
       "      <td>10.00</td>\n",
       "      <td>GIFTS_DONATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Amazon.com*HXXXWXXQX Amzn.com/bill WA XX/XX</td>\n",
       "      <td>33.20</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>CREDIT_CARD_PAYMENT</td>\n",
       "      <td>25.00</td>\n",
       "      <td>CREDIT_CARD_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>42.79</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prism_consumer_id prism_account_id  \\\n",
       "0                  0            acc_0   \n",
       "1                  0            acc_0   \n",
       "2                  0            acc_0   \n",
       "3                  0            acc_1   \n",
       "4                  0            acc_1   \n",
       "5                  0            acc_0   \n",
       "6                  0            acc_0   \n",
       "7                  0            acc_0   \n",
       "8                  0            acc_0   \n",
       "9                  0            acc_0   \n",
       "\n",
       "                                    memo_clean  amount category_description  \n",
       "0                                       Kroger   20.98            GROCERIES  \n",
       "1            CASH APP*FREE XXXXXXXXXX CA XX/XX  200.00  GENERAL_MERCHANDISE  \n",
       "2                                         LOAN  293.49                 LOAN  \n",
       "3                                SELF_TRANSFER  280.00        SELF_TRANSFER  \n",
       "4                            EXTERNAL_TRANSFER   47.83    EXTERNAL_TRANSFER  \n",
       "5                                SELF_TRANSFER   25.00        SELF_TRANSFER  \n",
       "6                              GIFTS_DONATIONS   10.00      GIFTS_DONATIONS  \n",
       "7  Amazon.com*HXXXWXXQX Amzn.com/bill WA XX/XX   33.20  GENERAL_MERCHANDISE  \n",
       "8                          CREDIT_CARD_PAYMENT   25.00  CREDIT_CARD_PAYMENT  \n",
       "9                                       Amazon   42.79  GENERAL_MERCHANDISE  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the first tenth datas in the dataset.\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2517037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the required categories and define a new dataset\n",
    "# which only contains these categories.\n",
    "categories_filter = ['GENERAL_MERCHANDISE', 'FOOD_AND_BEVERAGES', 'GROCERIES', 'TRAVEL', 'PETS', 'EDUCATION', 'OVERDRAFT', 'RENT', 'MORTGAGE']\n",
    "data1 = data[data['category_description'].isin(categories_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9e7d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only inlcude a subset of the dataset \n",
    "# to prevent running out of memory problem.\n",
    "data2 = data1[:50000]\n",
    "len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b34317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160/67511699.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Data Cleanning Process Part\n",
    "\n",
    "\n",
    "## Changing memo_clean column values to all lower case first.\n",
    "data2['memo_clean'] = data2['memo_clean'].str.lower()\n",
    "\n",
    "\n",
    "## Use regular expressions to remove text after \".com*\" \n",
    "## and keep the preceding text from \".com\"\n",
    "def clean_text1(text):\n",
    "    # Use regular expressions to remove text after \".com*\" and keep the preceding text from \".com\"\n",
    "    cleaned_text = re.sub(r'\\.com\\*.*?(?=\\s|$)', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "## Removing useless pattenrs\n",
    "def remove_key_phrases(text):\n",
    "    phrases = [\n",
    "        'pos debit - visa check card xxxx - ',\n",
    "        'purchase authorized on xx/xx',\n",
    "        'pos purchase',\n",
    "        'purchase',\n",
    "        'pos',\n",
    "        'web id',\n",
    "        'terminal id',\n",
    "        'id'\n",
    "    ]\n",
    "    for phrase in phrases:\n",
    "        text = re.sub(phrase, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "## Removing special characters.\n",
    "def remove_special_char(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "\n",
    "\n",
    "## Removing all the repeat 'x' patterns\n",
    "def remove_xs(text):\n",
    "    text = re.sub(r'(xx+)\\b', ' ', text)\n",
    "    text = re.sub(r'\\b(x)\\b', ' ', text)\n",
    "    text = re.sub(r'\\b(xx+)([a-zA-Z])', r'xx\\2', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "## Simplify repeating pattenrs for amazon and walmart\n",
    "def standardize_phrase(text):\n",
    "    text = re.sub(r'\\b(amazon|amzn|amz)\\b', 'amazon', text)\n",
    "    text = re.sub(r'\\b(wal\\smart|wal|wm\\ssupercenter|wm\\ssuperc|wm)\\b', 'walmart', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "## Removing multiple spaces\n",
    "def remove_multiple_spaces(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "524ed78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160/1525390538.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].apply(clean_text1)\n",
      "/tmp/ipykernel_160/1525390538.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].apply(remove_key_phrases)\n",
      "/tmp/ipykernel_160/1525390538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].apply(remove_special_char)\n",
      "/tmp/ipykernel_160/1525390538.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].apply(remove_xs)\n",
      "/tmp/ipykernel_160/1525390538.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].apply(standardize_phrase)\n",
      "/tmp/ipykernel_160/1525390538.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['memo_clean'] = data2['memo_clean'].apply(remove_multiple_spaces)\n"
     ]
    }
   ],
   "source": [
    "# Applying thoese cleaning functions to the subset of the dataset\n",
    "# that we choose.\n",
    "\n",
    "data2['memo_clean'] = data2['memo_clean'].apply(clean_text1)\n",
    "data2['memo_clean'] = data2['memo_clean'].apply(remove_key_phrases)\n",
    "data2['memo_clean'] = data2['memo_clean'].apply(remove_special_char)\n",
    "data2['memo_clean'] = data2['memo_clean'].apply(remove_xs)\n",
    "data2['memo_clean'] = data2['memo_clean'].apply(standardize_phrase)\n",
    "data2['memo_clean'] = data2['memo_clean'].apply(remove_multiple_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc50ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo_clean</th>\n",
       "      <th>amount</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>kroger</td>\n",
       "      <td>20.98</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>cash app free ca</td>\n",
       "      <td>200.00</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>amazon amazon com bill wa</td>\n",
       "      <td>33.20</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>42.79</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>kroger</td>\n",
       "      <td>36.55</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>paragon food beverage marksville la</td>\n",
       "      <td>12.65</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>instacart ca</td>\n",
       "      <td>22.83</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>ihop</td>\n",
       "      <td>10.00</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>12.69</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>habaneros fresh tex mex copperhill tn</td>\n",
       "      <td>10.34</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prism_consumer_id prism_account_id                             memo_clean  \\\n",
       "0                   0            acc_0                                 kroger   \n",
       "1                   0            acc_0                       cash app free ca   \n",
       "7                   0            acc_0              amazon amazon com bill wa   \n",
       "9                   0            acc_0                                 amazon   \n",
       "10                  0            acc_0                                 kroger   \n",
       "11                  0            acc_0    paragon food beverage marksville la   \n",
       "12                  0            acc_0                           instacart ca   \n",
       "14                  0            acc_0                                   ihop   \n",
       "15                  0            acc_0                                 amazon   \n",
       "17                  0            acc_0  habaneros fresh tex mex copperhill tn   \n",
       "\n",
       "    amount category_description  \n",
       "0    20.98            GROCERIES  \n",
       "1   200.00  GENERAL_MERCHANDISE  \n",
       "7    33.20  GENERAL_MERCHANDISE  \n",
       "9    42.79  GENERAL_MERCHANDISE  \n",
       "10   36.55            GROCERIES  \n",
       "11   12.65   FOOD_AND_BEVERAGES  \n",
       "12   22.83   FOOD_AND_BEVERAGES  \n",
       "14   10.00   FOOD_AND_BEVERAGES  \n",
       "15   12.69  GENERAL_MERCHANDISE  \n",
       "17   10.34   FOOD_AND_BEVERAGES  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset after cleanning.\n",
    "data2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9afe0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_description\n",
       "FOOD_AND_BEVERAGES     19091\n",
       "GENERAL_MERCHANDISE    18683\n",
       "GROCERIES               8730\n",
       "TRAVEL                  2251\n",
       "PETS                     530\n",
       "EDUCATION                254\n",
       "RENT                     226\n",
       "OVERDRAFT                148\n",
       "MORTGAGE                  87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check numbers of each categories.\n",
    "data2['category_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fb5b4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GROCERIES': 0,\n",
       " 'GENERAL_MERCHANDISE': 1,\n",
       " 'FOOD_AND_BEVERAGES': 2,\n",
       " 'TRAVEL': 3,\n",
       " 'PETS': 4,\n",
       " 'OVERDRAFT': 5,\n",
       " 'RENT': 6,\n",
       " 'EDUCATION': 7,\n",
       " 'MORTGAGE': 8}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign labels to each categories.\n",
    "\n",
    "labels = data2.category_description.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, label in enumerate(labels):\n",
    "    label_dict[label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f6d8166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160/2694981407.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['label'] = data2.category_description.replace(label_dict)\n"
     ]
    }
   ],
   "source": [
    "# Creating a label column for the dataset.\n",
    "\n",
    "data2['label'] = data2.category_description.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e41d7364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo_clean</th>\n",
       "      <th>amount</th>\n",
       "      <th>category_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>kroger</td>\n",
       "      <td>20.98</td>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>cash app free ca</td>\n",
       "      <td>200.00</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>amazon amazon com bill wa</td>\n",
       "      <td>33.20</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>42.79</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>kroger</td>\n",
       "      <td>36.55</td>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>paragon food beverage marksville la</td>\n",
       "      <td>12.65</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>instacart ca</td>\n",
       "      <td>22.83</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>ihop</td>\n",
       "      <td>10.00</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>12.69</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>habaneros fresh tex mex copperhill tn</td>\n",
       "      <td>10.34</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prism_consumer_id prism_account_id                             memo_clean  \\\n",
       "0                   0            acc_0                                 kroger   \n",
       "1                   0            acc_0                       cash app free ca   \n",
       "7                   0            acc_0              amazon amazon com bill wa   \n",
       "9                   0            acc_0                                 amazon   \n",
       "10                  0            acc_0                                 kroger   \n",
       "11                  0            acc_0    paragon food beverage marksville la   \n",
       "12                  0            acc_0                           instacart ca   \n",
       "14                  0            acc_0                                   ihop   \n",
       "15                  0            acc_0                                 amazon   \n",
       "17                  0            acc_0  habaneros fresh tex mex copperhill tn   \n",
       "\n",
       "    amount category_description  label  \n",
       "0    20.98            GROCERIES      0  \n",
       "1   200.00  GENERAL_MERCHANDISE      1  \n",
       "7    33.20  GENERAL_MERCHANDISE      1  \n",
       "9    42.79  GENERAL_MERCHANDISE      1  \n",
       "10   36.55            GROCERIES      0  \n",
       "11   12.65   FOOD_AND_BEVERAGES      2  \n",
       "12   22.83   FOOD_AND_BEVERAGES      2  \n",
       "14   10.00   FOOD_AND_BEVERAGES      2  \n",
       "15   12.69  GENERAL_MERCHANDISE      1  \n",
       "17   10.34   FOOD_AND_BEVERAGES      2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the current dataset\n",
    "data2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec55836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, validation and test sets using stratify.\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(data2['memo_clean'], data2['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=data2['label'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "957b87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from bert packages\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8bb374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text in all train, val and test datasets.\n",
    "# Set the max_length to 256 for safe.\n",
    "\n",
    "encoded_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "encoded_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(), \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(), \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "445e2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokenized list to tensors\n",
    "\n",
    "input_ids_train = encoded_train['input_ids']\n",
    "attention_masks_train = encoded_train['attention_mask']\n",
    "labels_train = torch.tensor(train_labels.tolist())\n",
    "\n",
    "input_ids_val = encoded_val['input_ids']\n",
    "attention_masks_val = encoded_val['attention_mask']\n",
    "labels_val = torch.tensor(val_labels.tolist())\n",
    "\n",
    "input_ids_test = encoded_test['input_ids']\n",
    "attention_masks_test = encoded_test['attention_mask']\n",
    "labels_test = torch.tensor(test_labels.tolist())\n",
    "\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6b8e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and push to the device which we defined at the beginning.\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e60fe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the batch size to three\n",
    "# Using RandomSampler to randomly sample the training set.\n",
    "# Using SequentialSampler for validation set to sequentially test the data.\n",
    "# Using DataLoaer to improve efficient iteration and batching the data\n",
    "# during training and validation.\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), \n",
    "                                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e94616bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kzou/.local/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define an optimizer\n",
    "# Setting the epochs to be five\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d5c840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the perfomance metrics through F1_Score and Accuracy Score\n",
    "\n",
    "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "## Calculate the F1 score for a multi-class classification task.\n",
    "## Args: preds-Predicted labels,  labels-True labels\n",
    "def f1_func(preds, labels):\n",
    "    p = np.argmax(preds, axis=1).flatten()\n",
    "    l = labels.flatten()\n",
    "    f1 = f1_score(l, p, average='weighted')\n",
    "    return f1\n",
    "\n",
    "\n",
    "## Calculate and print accuracy for each class\n",
    "## Calculate and print overal accuracy score\n",
    "## Args: preds-Predicted labels,  labels-True labels, lab_dict_inverse-Inverse label dictionary\n",
    "def accuracy_per_class(preds, labels, label_dict_inverse):\n",
    "    p = np.argmax(preds, axis=1).flatten()\n",
    "    l = labels.flatten()\n",
    "\n",
    "    class_accuracies = {}\n",
    "    for label in np.unique(l):\n",
    "        mask = l == label\n",
    "        y_preds = p[mask]\n",
    "        y_true = l[mask]\n",
    "        class_name = label_dict_inverse[label]\n",
    "        class_accuracy = accuracy_score(y_true, y_preds)\n",
    "        class_accuracies[class_name] = class_accuracy\n",
    "\n",
    "    overall_accuracy = accuracy_score(l, p)\n",
    "\n",
    "    # Print class accuracies\n",
    "    for class_name, class_accuracy in class_accuracies.items():\n",
    "        print(f'Class: {class_name}\\nAccuracy: {class_accuracy:.2%}\\n')\n",
    "\n",
    "    # Print overall accuracy\n",
    "    print(f'Overall Accuracy: {overall_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fef4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03c4d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluate function\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b119b8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7850258779547a2b46278d992e0e27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/11667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.39854813014562046\n",
      "Validation loss: 0.16096235417008284\n",
      "F1 Score (Weighted): 0.9702427704940141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/11667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.13115647523666576\n",
      "Validation loss: 0.13700231841203786\n",
      "F1 Score (Weighted): 0.9766724955401223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/11667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.0636162499348864\n",
      "Validation loss: 0.15992878766612048\n",
      "F1 Score (Weighted): 0.9778683357732633\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/11667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.03264053829085513\n",
      "Validation loss: 0.17659580529846824\n",
      "F1 Score (Weighted): 0.9795875771106163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/11667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.015520779647802779\n",
      "Validation loss: 0.17451936516817224\n",
      "F1 Score (Weighted): 0.9805299765911736\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "    torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d51f4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: GROCERIES\n",
      "Accuracy: 99.24%\n",
      "\n",
      "Class: GENERAL_MERCHANDISE\n",
      "Accuracy: 98.18%\n",
      "\n",
      "Class: FOOD_AND_BEVERAGES\n",
      "Accuracy: 97.97%\n",
      "\n",
      "Class: TRAVEL\n",
      "Accuracy: 94.07%\n",
      "\n",
      "Class: PETS\n",
      "Accuracy: 97.47%\n",
      "\n",
      "Class: OVERDRAFT\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Class: RENT\n",
      "Accuracy: 91.18%\n",
      "\n",
      "Class: EDUCATION\n",
      "Accuracy: 76.32%\n",
      "\n",
      "Class: MORTGAGE\n",
      "Accuracy: 92.31%\n",
      "\n",
      "Overall Accuracy: 97.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1309\n",
      "           1       0.98      0.98      0.98      2803\n",
      "           2       0.98      0.98      0.98      2864\n",
      "           3       0.98      0.94      0.96       337\n",
      "           4       0.97      0.97      0.97        79\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       1.00      0.91      0.95        34\n",
      "           7       0.97      0.76      0.85        38\n",
      "           8       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98      7500\n",
      "   macro avg       0.98      0.94      0.96      7500\n",
      "weighted avg       0.98      0.98      0.98      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy per calss and the overall Acurracy Score\n",
    "# Caculating the precision, recall, and f1-score\n",
    "_, predictions, true_vals = evaluate(dataloader_test)\n",
    "accuracy_per_class(predictions, true_vals, label_dict_inverse)\n",
    "\n",
    "preds = np.argmax(predictions, axis = 1)\n",
    "print(classification_report(labels_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716dfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
